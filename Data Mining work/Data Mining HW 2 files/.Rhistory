library(tidyverse)
library(mosaic)
my_mod <- lm(price ~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction + lotSize*landValue, data = houses)
houses_split = initial_split(houses, prop = .8)
houses_train = training(houses_split)
houses_test = testing(houses_split)
rmse(my_mod,houses_test)
library(Metrics)
rmse(my_mod,houses_test)
my_mod <- lm(price ~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction + lotSize*landValue, data = houses)
houses_split = initial_split(houses, prop = .8)
houses_train = training(houses_split)
houses_test = testing(houses_split)
rmse(my_mod,houses_test)
?rmse
library(modelr)
rmse(my_mod,houses_test)
coef(my_mod)
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
?doMC
registerDoMC(cores=4)
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
LOO = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
medium_train = update(lm_medium, data=saratoga_train)
my_mod_train = update(my_mod, data=saratoga_train)
medium_test = predict(medium_train, saratoga_test)
yhat_mine_test = predict(my_mod_train, saratoga_test)
# check performance
mse_medium = (medium_test - saratoga_test$price)^2
mse_mine = (my_test - saratoga_test$price)^2
# return results from the loop
c(mse_medium, mse_mine)
}
N = nrow(SaratogaHouses)
LOO = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
medium_train = update(lm_medium, data=saratoga_train)
my_mod_train = update(my_mod, data=saratoga_train)
medium_test = predict(medium_train, saratoga_test)
yhat_mine_test = predict(my_mod_train, saratoga_test)
# check performance
mse_medium = (medium_test - saratoga_test$price)^2
mse_mine = (my_test - saratoga_test$price)^2
# return results from the loop
c(mse_medium, mse_mine)
}
my_test = predict(my_mod_train, saratoga_test)
LOO = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
medium_train = update(lm_medium, data=saratoga_train)
my_mod_train = update(my_mod, data=saratoga_train)
medium_test = predict(medium_train, saratoga_test)
my_test = predict(my_mod_train, saratoga_test)
# check performance
mse_medium = (medium_test - saratoga_test$price)^2
mse_mine = (my_test - saratoga_test$price)^2
# return results from the loop
c(mse_medium, mse_mine)
}
sqrt(colMeans(LOO))
coef(my_mod)
summary(my_mod)
library(tidyverse)
library(mosaic)
library(Metrics)
library(modelr)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
ggplot(mod_spec_out) + geom_boxplot(aes(x=factor(k), y=rmse)) + theme_bw(base_size=7)
mod_spec = model.matrix(~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction -1, data = houses)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
data("SaratogaHouses")
houses <- SaratogaHouses
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
lm_medium = lm(price ~ lotSize + age + livingArea + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
# baseline medium model with 11 main effects
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
## rmse ranged from 62000 to 75000 ish
library(tidyverse)
library(mosaic)
library(Metrics)
library(modelr)
my_mod <- lm(price ~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction + lotSize*landValue, data = houses)
houses_split = initial_split(houses, prop = .8)
houses_train = training(houses_split)
houses_test = testing(houses_split)
rmse(my_mod,houses_test)
library(tidyverse)
library(mosaic)
library(Metrics)
library(modelr)
my_mod <- lm(price ~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction + lotSize*landValue, data = houses)
houses_split = initial_split(houses, prop = .8)
houses_train = training(houses_split)
houses_test = testing(houses_split)
registerDoMC(cores=4)
rmse = function(y, yhat) {sqrt( mean( (y - yhat)^2 ))}
N = nrow(SaratogaHouses)
LOO = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
medium_train = update(lm_medium, data=saratoga_train)
my_mod_train = update(my_mod, data=saratoga_train)
medium_test = predict(medium_train, saratoga_test)
my_test = predict(my_mod_train, saratoga_test)
mse_medium = (medium_test - saratoga_test$price)^2
mse_mine = (my_test - saratoga_test$price)^2
c(mse_medium, mse_mine)
}
sqrt(colMeans(LOO))
mod_spec = model.matrix(~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction -1, data = houses)
feature_sd = apply(mod_spec, 2, sd)
mod_std = scale(mod_spec, scale=feature_sd)
N= nrow(houses)
#KNN Code
k_val = k_val = c(2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300)
mod_spec_out = foreach(i=1:N, .combine='rbind') %dopar% {
mod_train = mod_std[-i,]
mod_test = mod_std[i,]
y_train = houses$price[-i]
y_test = houses$price[i]
mod_mse_out = foreach(k = k_val, .combine='c') %do% {
knn_fit = knn.reg(mod_train, mod_test, y_train, k)
(y_test - knn_fit$pred)^2
}
mod_mse_out
}
rmse = sqrt(colMeans(mod_spec_out))
mod_spec_out <- data.frame(k = k_val, rmse = rmse)
ggplot(mod_spec_out) + geom_boxplot(aes(x=factor(k), y=rmse)) + theme_bw(base_size=7)
credit_data <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/german_credit.csv")
logit1 <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, data = credit_data, family = "binomial")
df1 <- data.frame(default.probability = logit1$fitted.values, credit.history = credit_data$history)
df2 <- df1 %>%
group_by(credit.history) %>%
summarise(avg.default.prob = mean(default.probability))
plot.3.a <- ggplot(data = df2, mapping = aes(x = credit.history, y = avg.default.prob ), fill = "blue") +
geom_col()+
labs(
title = "Average Default Probability by Credit History",
x = "Credit History",
y = "Default Probability"
)+
theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
plot.3.a
knitr::opts_chunk$set(echo = TRUE)
hotel.dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
install.packages("cvTools")
library(cvTools) #run the above line if you don't have this library
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
install.packages("cvTools")
hotel.dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
library(cvTools) #run the above line if you don't have this library
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
hotel.dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")
hotel.val <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
for(i in 1:k){
train <- hotel.val[folds$subsets[folds$which != i], ] #Set the training set
validation <- hotel.val[folds$subsets[folds$which == i], ] #Set the validation set
stepmod2 <- glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = train) #fit on the hotel.val train data)
newpred <- predict(stepmod2,newdata=validation) #Predictions for the validation set
}
newpred
knitr::opts_chunk$set(echo = TRUE)
library(doMC)
install.packages("cvTools")
install.packages("cvTools")
library(cvTools) #run the above line if you don't have this library
install.packages("cvTools")
library(cvTools) #run the above line if you don't have this library
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
hotel.val$holdoutpred <- rep(0,nrow(hotel.val))
for(i in 1:k){
train <- hotel.val[folds$subsets[folds$which != i], ] #Set the training set
validation <- hotel.val[folds$subsets[folds$which == i], ] #Set the validation set
stepmod2 <- glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = train) #fit on the hotel.val train data)
newpred <- predict(stepmod2,newdata=validation) #Predictions for the validation set
}
newpred
install.packages("cvTools")
library(tidyverse)
library(ggplot2)
library(rsample)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
library(mosaic)
library(foreach)
library(doMC)  # for parallel computing
library(Metrics)
library(gamlr)
hotel.dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
hotel.dev.split = initial_split(hotel.dev, prop = .8)
hotel.dev.train = training(hotel.dev.split)
hotel.dev.test = testing(hotel.dev.split)
small_mod = glm(children ~ market_segment + adults + customer_type + is_repeated_guest, data = hotel.dev.train, family = "binomial")
big_mod = glm(children ~ . -arrival_date, data = hotel.dev.train, family = "binomial")
##step_mod2 <- step(big_mod,
##                 scope=~(.))
##I ran step_mod2 using the step command then decided to represent it as a normal logit model to speed up processing times when knitting
step_mod2 = glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = hotel.dev.train)
AICs <- data.frame(AICs = c(AICc(step_mod2), AICc(small_mod), AICc(big_mod)), Model = c("step_mod2", "small_mod", "big_mod"))
AICs
hotel.val <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")
phat_test_step = predict(step_mod2, hotel.val, type='response')
thresh_grid = seq(0.95, 0.05, by=-0.005)
roc_curve_step = foreach(thresh = thresh_grid, .combine='rbind') %do% {
yhat_test_step = ifelse(phat_test_step>= thresh, 1, 0)
# FPR, TPR for linear model
confusion_out_step = table(y = hotel.val$children, yhat = yhat_test_step)
out_step = data.frame(model = "logit",
TPR = confusion_out_step[2,2]/sum(hotel.val$children==1),
FPR = confusion_out_step[1,2]/sum(hotel.val$children==0))
rbind(out_step)
} %>% as.data.frame()
ROCgraph <- ggplot(roc_curve_step) +
geom_line(aes(x=FPR, y=TPR, color=model)) +
labs(title="ROC curve for step_mod2") +
theme(plot.title = element_text(hjust = 0.5))
ROCgraph
install.packages("cvTools")
library(cvTools) #run the above line if you don't have this library
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
hotel.val$holdoutpred <- rep(0,nrow(hotel.val))
for(i in 1:k){
train <- hotel.val[folds$subsets[folds$which != i], ] #Set the training set
validation <- hotel.val[folds$subsets[folds$which == i], ] #Set the validation set
stepmod2 <- glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = train) #fit on the hotel.val train data)
newpred <- predict(stepmod2,newdata=validation) #Predictions for the validation set
}
newpred
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(tidyverse)
library(ggplot2)
library(curl)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
capmetro_UT <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/capmetro_UT.csv")
# Recode the categorical variables in sensible, rather than alphabetical, order
capmetro_UT = mutate(capmetro_UT,
day_of_week = factor(day_of_week,
levels=c("Mon", "Tue", "Wed","Thu", "Fri", "Sat", "Sun")),
month = factor(month,
levels=c("Sep", "Oct","Nov")))
update.packages(ask = FALSE, checkBuilt = TRUE)
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
library(magrittr)
library(tidyverse)
library(ggplot2)
library(curl)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
capmetro_UT <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/capmetro_UT.csv")
# Recode the categorical variables in sensible, rather than alphabetical, order
capmetro_UT = mutate(capmetro_UT,
day_of_week = factor(day_of_week,
levels=c("Mon", "Tue", "Wed","Thu", "Fri", "Sat", "Sun")),
month = factor(month,
levels=c("Sep", "Oct","Nov")))
## group, pipe, summarize plot 1a
pan1 <- capmetro_UT %>%
group_by(hour_of_day, day_of_week, month) %>%
summarize(totalhr = sum(boarding),
avg_per_hr = totalhr/n(),
day_of_week = day_of_week,
month = month)
## Avg hourly boarding for Sept, Oct, Nov faceted on day of week
plot.1.a <- ggplot(data = pan1, aes(x = hour_of_day, y = avg_per_hr)) +
geom_line(aes(color = month)) +
facet_wrap(~day_of_week) +
labs(
title = "Average Hourly Boarding for September, October, November by Day of Week",
x="Hour of Day",
y="Average Boarding per Hour"
) +
theme(plot.title = element_text(hjust = 0.5), legend.position = "right")
plot.1.a
## group, pipe summarize plot 1b
pan2 <-  capmetro_UT %>%
summarize(board = boarding,
temp = temperature,
hour = hour_of_day,
weekend = weekend)
## Scatter of boarding and temperature faceted on hour of day
plot.1.b <- ggplot(data = pan2) +
geom_point(alpha = .25, mapping = aes(x = temp, y = board, color = weekend)) +
facet_wrap(~hour) +
labs(
title = "Ridership vs Temperature by Hour of Day",
x="Temperature",
y="Ridership"
) +
theme(plot.title = element_text(hjust = 0.5), legend.position = "right")
plot.1.b
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
data("SaratogaHouses")
houses <- SaratogaHouses
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
lm_medium = lm(price ~ lotSize + age + livingArea + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
# baseline medium model with 11 main effects
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
## rmse ranged from 62000 to 75000 ish
library(tidyverse)
library(mosaic)
library(Metrics)
library(modelr)
library(doMC)
my_mod <- lm(price ~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction + lotSize*landValue, data = houses)
houses_split = initial_split(houses, prop = .8)
houses_train = training(houses_split)
houses_test = testing(houses_split)
registerDoMC(cores=4)
rmse = function(y, yhat) {sqrt( mean( (y - yhat)^2 ))}
N = nrow(SaratogaHouses)
LOO = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
medium_train = update(lm_medium, data=saratoga_train)
my_mod_train = update(my_mod, data=saratoga_train)
medium_test = predict(medium_train, saratoga_test)
my_test = predict(my_mod_train, saratoga_test)
mse_medium = (medium_test - saratoga_test$price)^2
mse_mine = (my_test - saratoga_test$price)^2
c(mse_medium, mse_mine)
}
sqrt(colMeans(LOO))
mod_spec = model.matrix(~ lotSize + age + landValue + bedrooms + bathrooms + rooms + waterfront + newConstruction -1, data = houses)
feature_sd = apply(mod_spec, 2, sd)
mod_std = scale(mod_spec, scale=feature_sd)
N= nrow(houses)
#KNN Code
k_val = k_val = c(2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300)
mod_spec_out = foreach(i=1:N, .combine='rbind') %dopar% {
mod_train = mod_std[-i,]
mod_test = mod_std[i,]
y_train = houses$price[-i]
y_test = houses$price[i]
mod_mse_out = foreach(k = k_val, .combine='c') %do% {
knn_fit = knn.reg(mod_train, mod_test, y_train, k)
(y_test - knn_fit$pred)^2
}
mod_mse_out
}
rmse = sqrt(colMeans(mod_spec_out))
mod_spec_out <- data.frame(k = k_val, rmse = rmse)
ggplot(mod_spec_out) + geom_boxplot(aes(x=factor(k), y=rmse)) + theme_bw(base_size=7)
credit_data <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/german_credit.csv")
logit1 <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, data = credit_data, family = "binomial")
df1 <- data.frame(default.probability = logit1$fitted.values, credit.history = credit_data$history)
df2 <- df1 %>%
group_by(credit.history) %>%
summarise(avg.default.prob = mean(default.probability))
plot.3.a <- ggplot(data = df2, mapping = aes(x = credit.history, y = avg.default.prob ), fill = "blue") +
geom_col()+
labs(
title = "Average Default Probability by Credit History",
x = "Credit History",
y = "Default Probability"
)+
theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
plot.3.a
library(tidyverse)
library(ggplot2)
library(rsample)
library(parallel)
library(caret)
library(foreach)
library(FNN)
library(rsample)
library(modelr)
library(mosaic)
library(foreach)
library(doMC)  # for parallel computing
library(Metrics)
library(gamlr)
hotel.dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
hotel.dev.split = initial_split(hotel.dev, prop = .8)
hotel.dev.train = training(hotel.dev.split)
hotel.dev.test = testing(hotel.dev.split)
small_mod = glm(children ~ market_segment + adults + customer_type + is_repeated_guest, data = hotel.dev.train, family = "binomial")
big_mod = glm(children ~ . -arrival_date, data = hotel.dev.train, family = "binomial")
##step_mod2 <- step(big_mod,
##                 scope=~(.))
##I ran step_mod2 using the step command then decided to represent it as a normal logit model to speed up processing times when knitting
step_mod2 = glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = hotel.dev.train)
AICs <- data.frame(AICs = c(AICc(step_mod2), AICc(small_mod), AICc(big_mod)), Model = c("step_mod2", "small_mod", "big_mod"))
AICs
hotel.val <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")
phat_test_step = predict(step_mod2, hotel.val, type='response')
thresh_grid = seq(0.95, 0.05, by=-0.005)
roc_curve_step = foreach(thresh = thresh_grid, .combine='rbind') %do% {
yhat_test_step = ifelse(phat_test_step>= thresh, 1, 0)
# FPR, TPR for linear model
confusion_out_step = table(y = hotel.val$children, yhat = yhat_test_step)
out_step = data.frame(model = "logit",
TPR = confusion_out_step[2,2]/sum(hotel.val$children==1),
FPR = confusion_out_step[1,2]/sum(hotel.val$children==0))
rbind(out_step)
} %>% as.data.frame()
ROCgraph <- ggplot(roc_curve_step) +
geom_line(aes(x=FPR, y=TPR, color=model)) +
labs(title="ROC curve for step_mod2") +
theme(plot.title = element_text(hjust = 0.5))
ROCgraph
install.packages("cvTools")
library(cvTools) #run the above line if you don't have this library
k <- 20 #the number of folds
folds <- cvFolds(NROW(hotel.val), K=k)
hotel.val$holdoutpred <- rep(0,nrow(hotel.val))
for(i in 1:k){
train <- hotel.val[folds$subsets[folds$which != i], ] #Set the training set
validation <- hotel.val[folds$subsets[folds$which == i], ] #Set the validation set
stepmod2 <- glm(formula = children ~ hotel + lead_time + stays_in_weekend_nights +
stays_in_week_nights + adults + meal + market_segment + distribution_channel +
is_repeated_guest + previous_bookings_not_canceled + reserved_room_type +
assigned_room_type + booking_changes + customer_type + average_daily_rate +
required_car_parking_spaces + total_of_special_requests,
family = "binomial", data = train) #fit on the hotel.val train data)
newpred <- predict(stepmod2,newdata=validation) #Predictions for the validation set
}
newpred
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
